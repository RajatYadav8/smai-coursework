{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./intrusion_detection/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>xAttack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>193</td>\n",
       "      <td>441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>167</td>\n",
       "      <td>9724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  service  src_bytes  dst_bytes  hot  num_failed_logins  \\\n",
       "0         0       25        193        441    0                  0   \n",
       "1         0       38          0          0    0                  0   \n",
       "2         0       25        167       9724    0                  0   \n",
       "3         0       20       1339          0    0                  0   \n",
       "4         0       37          0          0    0                  0   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files   ...     \\\n",
       "0                0         0                   0                 0   ...      \n",
       "1                0         0                   0                 0   ...      \n",
       "2                0         0                   0                 0   ...      \n",
       "3                0         0                   0                 0   ...      \n",
       "4                0         0                   0                 0   ...      \n",
       "\n",
       "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                 255                    1.00                    0.00   \n",
       "1                   1                    0.00                    0.07   \n",
       "2                 255                    1.00                    0.00   \n",
       "3                  31                    0.23                    0.04   \n",
       "4                  25                    0.10                    0.05   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.07                         0.04   \n",
       "1                         0.00                         0.00   \n",
       "2                         0.03                         0.06   \n",
       "3                         0.23                         0.00   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.04                   0.0   \n",
       "1                  0.00                      0.00                   1.0   \n",
       "2                  0.00                      0.00                   0.0   \n",
       "3                  0.02                      0.00                   0.0   \n",
       "4                  1.00                      1.00                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate  xAttack  \n",
       "0                       0.0   normal  \n",
       "1                       1.0      dos  \n",
       "2                       0.0   normal  \n",
       "3                       0.0   normal  \n",
       "4                       0.0      dos  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>2.499800e+04</td>\n",
       "      <td>2.499800e+04</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>310.648452</td>\n",
       "      <td>32.024842</td>\n",
       "      <td>2.442409e+04</td>\n",
       "      <td>3.305597e+03</td>\n",
       "      <td>0.193535</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.229418</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.004360</td>\n",
       "      <td>...</td>\n",
       "      <td>182.405832</td>\n",
       "      <td>115.254580</td>\n",
       "      <td>0.520648</td>\n",
       "      <td>0.083117</td>\n",
       "      <td>0.148392</td>\n",
       "      <td>0.032109</td>\n",
       "      <td>0.284272</td>\n",
       "      <td>0.278418</td>\n",
       "      <td>0.118272</td>\n",
       "      <td>0.119189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2712.235502</td>\n",
       "      <td>16.493033</td>\n",
       "      <td>2.420103e+06</td>\n",
       "      <td>8.301712e+04</td>\n",
       "      <td>2.127846</td>\n",
       "      <td>0.045594</td>\n",
       "      <td>10.457662</td>\n",
       "      <td>11.545358</td>\n",
       "      <td>0.531652</td>\n",
       "      <td>0.098905</td>\n",
       "      <td>...</td>\n",
       "      <td>99.046209</td>\n",
       "      <td>110.659088</td>\n",
       "      <td>0.449020</td>\n",
       "      <td>0.188442</td>\n",
       "      <td>0.309335</td>\n",
       "      <td>0.111102</td>\n",
       "      <td>0.444531</td>\n",
       "      <td>0.445374</td>\n",
       "      <td>0.306349</td>\n",
       "      <td>0.317858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.790000e+02</td>\n",
       "      <td>5.310000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42862.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.817091e+08</td>\n",
       "      <td>5.150836e+06</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>975.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration       service     src_bytes     dst_bytes           hot  \\\n",
       "count  24998.000000  24998.000000  2.499800e+04  2.499800e+04  24998.000000   \n",
       "mean     310.648452     32.024842  2.442409e+04  3.305597e+03      0.193535   \n",
       "std     2712.235502     16.493033  2.420103e+06  8.301712e+04      2.127846   \n",
       "min        0.000000      1.000000  0.000000e+00  0.000000e+00      0.000000   \n",
       "25%        0.000000     20.000000  0.000000e+00  0.000000e+00      0.000000   \n",
       "50%        0.000000     25.000000  4.400000e+01  0.000000e+00      0.000000   \n",
       "75%        0.000000     50.000000  2.790000e+02  5.310000e+02      0.000000   \n",
       "max    42862.000000     70.000000  3.817091e+08  5.150836e+06     77.000000   \n",
       "\n",
       "       num_failed_logins  num_compromised      num_root  num_file_creations  \\\n",
       "count       24998.000000     24998.000000  24998.000000        24998.000000   \n",
       "mean            0.001200         0.229418      0.251700            0.014841   \n",
       "std             0.045594        10.457662     11.545358            0.531652   \n",
       "min             0.000000         0.000000      0.000000            0.000000   \n",
       "25%             0.000000         0.000000      0.000000            0.000000   \n",
       "50%             0.000000         0.000000      0.000000            0.000000   \n",
       "75%             0.000000         0.000000      0.000000            0.000000   \n",
       "max             4.000000       884.000000    975.000000           40.000000   \n",
       "\n",
       "       num_access_files            ...             dst_host_count  \\\n",
       "count      24998.000000            ...               24998.000000   \n",
       "mean           0.004360            ...                 182.405832   \n",
       "std            0.098905            ...                  99.046209   \n",
       "min            0.000000            ...                   0.000000   \n",
       "25%            0.000000            ...                  84.000000   \n",
       "50%            0.000000            ...                 255.000000   \n",
       "75%            0.000000            ...                 255.000000   \n",
       "max            8.000000            ...                 255.000000   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count        24998.000000            24998.000000            24998.000000   \n",
       "mean           115.254580                0.520648                0.083117   \n",
       "std            110.659088                0.449020                0.188442   \n",
       "min              0.000000                0.000000                0.000000   \n",
       "25%             10.000000                0.050000                0.000000   \n",
       "50%             62.000000                0.510000                0.030000   \n",
       "75%            255.000000                1.000000                0.070000   \n",
       "max            255.000000                1.000000                1.000000   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                 24998.000000                 24998.000000   \n",
       "mean                      0.148392                     0.032109   \n",
       "std                       0.309335                     0.111102   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.060000                     0.020000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count          24998.000000              24998.000000          24998.000000   \n",
       "mean               0.284272                  0.278418              0.118272   \n",
       "std                0.444531                  0.445374              0.306349   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  0.000000              0.000000   \n",
       "50%                0.000000                  0.000000              0.000000   \n",
       "75%                1.000000                  1.000000              0.000000   \n",
       "max                1.000000                  1.000000              1.000000   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count              24998.000000  \n",
       "mean                   0.119189  \n",
       "std                    0.317858  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    0.000000  \n",
       "max                    1.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preProcessor:\n",
    "    def __init__(self):\n",
    "        self.scalar = StandardScaler()\n",
    "    def fit(self, df, features):\n",
    "        # Separating out the features\n",
    "        x = df[features]\n",
    "        self.scalar = StandardScaler().fit(x)\n",
    "    def transform(self, df, features):\n",
    "        rest = [col for col in df.columns.values if col not in features]\n",
    "        res = pd.DataFrame(self.scalar.transform(df), columns=features)\n",
    "#         print(res)\n",
    "        res[rest] = df[rest]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['duration', 'service', 'src_bytes', 'dst_bytes', 'hot',\n",
       "       'num_failed_logins', 'num_compromised', 'num_root',\n",
       "       'num_file_creations', 'num_access_files', 'count', 'srv_count',\n",
       "       'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
       "       'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',\n",
       "       'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
       "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
       "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
       "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
       "       'dst_host_srv_rerror_rate'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'xAttack'\n",
    "features = df.columns.values[[df.columns.values != 'xAttack']]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = preProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.fit(df[features], features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard = processor.transform(df[features], features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010013</td>\n",
       "      <td>-0.034507</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.690213</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.253425</td>\n",
       "      <td>0.071030</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.535332</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.362291</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732947</td>\n",
       "      <td>-1.032512</td>\n",
       "      <td>-1.159545</td>\n",
       "      <td>-0.069609</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>2.878240</td>\n",
       "      <td>2.771138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010023</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.447897</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.382738</td>\n",
       "      <td>0.251048</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.729101</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488729</td>\n",
       "      <td>-0.761404</td>\n",
       "      <td>-0.647308</td>\n",
       "      <td>-0.228812</td>\n",
       "      <td>0.263823</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.594507</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.301658</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732947</td>\n",
       "      <td>-0.815626</td>\n",
       "      <td>-0.936833</td>\n",
       "      <td>-0.175745</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>1.610108</td>\n",
       "      <td>1.620205</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   service  src_bytes  dst_bytes       hot  num_failed_logins  \\\n",
       "0 -0.114538 -0.425936  -0.010013  -0.034507 -0.090956          -0.026322   \n",
       "1 -0.114538  0.362291  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "2 -0.114538 -0.425936  -0.010023   0.077316 -0.090956          -0.026322   \n",
       "3 -0.114538 -0.729101  -0.009539  -0.039819 -0.090956          -0.026322   \n",
       "4 -0.114538  0.301658  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files  \\\n",
       "0        -0.021938 -0.021801           -0.027916         -0.044087   \n",
       "1        -0.021938 -0.021801           -0.027916         -0.044087   \n",
       "2        -0.021938 -0.021801           -0.027916         -0.044087   \n",
       "3        -0.021938 -0.021801           -0.027916         -0.044087   \n",
       "4        -0.021938 -0.021801           -0.027916         -0.044087   \n",
       "\n",
       "             ...             dst_host_count  dst_host_srv_count  \\\n",
       "0            ...                  -1.690213            1.262872   \n",
       "1            ...                   0.732947           -1.032512   \n",
       "2            ...                  -1.447897            1.262872   \n",
       "3            ...                  -0.488729           -0.761404   \n",
       "4            ...                   0.732947           -0.815626   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                1.067572               -0.441083   \n",
       "1               -1.159545               -0.069609   \n",
       "2                1.067572               -0.441083   \n",
       "3               -0.647308               -0.228812   \n",
       "4               -0.936833               -0.175745   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                    -0.253425                     0.071030   \n",
       "1                    -0.479722                    -0.289006   \n",
       "2                    -0.382738                     0.251048   \n",
       "3                     0.263823                    -0.289006   \n",
       "4                    -0.479722                    -0.289006   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0             -0.639500                 -0.535332             -0.386077   \n",
       "1             -0.639500                 -0.625146              2.878240   \n",
       "2             -0.639500                 -0.625146             -0.386077   \n",
       "3             -0.594507                 -0.625146             -0.386077   \n",
       "4              1.610108                  1.620205             -0.386077   \n",
       "\n",
       "   dst_host_srv_rerror_rate  \n",
       "0                 -0.374982  \n",
       "1                  2.771138  \n",
       "2                 -0.374982  \n",
       "3                 -0.374982  \n",
       "4                 -0.374982  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard[target] = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>xAttack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010013</td>\n",
       "      <td>-0.034507</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.253425</td>\n",
       "      <td>0.071030</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.535332</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.362291</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.032512</td>\n",
       "      <td>-1.159545</td>\n",
       "      <td>-0.069609</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>2.878240</td>\n",
       "      <td>2.771138</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010023</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.382738</td>\n",
       "      <td>0.251048</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.729101</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761404</td>\n",
       "      <td>-0.647308</td>\n",
       "      <td>-0.228812</td>\n",
       "      <td>0.263823</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.594507</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.301658</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815626</td>\n",
       "      <td>-0.936833</td>\n",
       "      <td>-0.175745</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>1.610108</td>\n",
       "      <td>1.620205</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   service  src_bytes  dst_bytes       hot  num_failed_logins  \\\n",
       "0 -0.114538 -0.425936  -0.010013  -0.034507 -0.090956          -0.026322   \n",
       "1 -0.114538  0.362291  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "2 -0.114538 -0.425936  -0.010023   0.077316 -0.090956          -0.026322   \n",
       "3 -0.114538 -0.729101  -0.009539  -0.039819 -0.090956          -0.026322   \n",
       "4 -0.114538  0.301658  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files   ...     \\\n",
       "0        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "1        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "2        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "3        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "4        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "\n",
       "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0            1.262872                1.067572               -0.441083   \n",
       "1           -1.032512               -1.159545               -0.069609   \n",
       "2            1.262872                1.067572               -0.441083   \n",
       "3           -0.761404               -0.647308               -0.228812   \n",
       "4           -0.815626               -0.936833               -0.175745   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                    -0.253425                     0.071030   \n",
       "1                    -0.479722                    -0.289006   \n",
       "2                    -0.382738                     0.251048   \n",
       "3                     0.263823                    -0.289006   \n",
       "4                    -0.479722                    -0.289006   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0             -0.639500                 -0.535332             -0.386077   \n",
       "1             -0.639500                 -0.625146              2.878240   \n",
       "2             -0.639500                 -0.625146             -0.386077   \n",
       "3             -0.594507                 -0.625146             -0.386077   \n",
       "4              1.610108                  1.620205             -0.386077   \n",
       "\n",
       "   dst_host_srv_rerror_rate  xAttack  \n",
       "0                 -0.374982   normal  \n",
       "1                  2.771138      dos  \n",
       "2                 -0.374982   normal  \n",
       "3                 -0.374982   normal  \n",
       "4                 -0.374982      dos  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART-1 My PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPCA:\n",
    "    def __init__(self, n_components = None):\n",
    "        self.n_components = n_components\n",
    "    def fit(self, df):\n",
    "        margin = 10\n",
    "        self.cols = df.columns.values\n",
    "        x = df.values\n",
    "        covar = np.dot(x.T,x)\n",
    "        self.u, self.s, self.vh = np.linalg.svd(x, full_matrices=False)\n",
    "        if(self.n_components is None):\n",
    "            k = len(self.s)\n",
    "        else:\n",
    "            k = self.n_components\n",
    "        cum_sum = 0.0\n",
    "        tot_sum = np.sum(np.square(self.s))\n",
    "        for i in range(len(self.s)):\n",
    "            cum_sum += self.s[i]**2\n",
    "            if(cum_sum/tot_sum*100 >= 90):\n",
    "                self.n_components = i + 1\n",
    "                break\n",
    "        self.V = self.vh.T[:,:self.n_components]\n",
    "    def transform(self, df):\n",
    "        new_cols = ['PCA_']*len(self.V[0])\n",
    "        for i in range(len(new_cols)):\n",
    "            new_cols[i] = new_cols[i] + str(i+1)\n",
    "        return pd.DataFrame(np.dot(df,self.V),columns=new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPCA = MyPCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPCA.fit(df_standard[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23233278, 0.40004825, 0.49014959, 0.55525906, 0.60602914,\n",
       "       0.65238779, 0.69158857, 0.72800063, 0.76269096, 0.79709466,\n",
       "       0.83029625, 0.86198573, 0.88670879, 0.90931903, 0.92645134,\n",
       "       0.94188281, 0.95609327, 0.96995871, 0.98186236, 0.98911049,\n",
       "       0.9924583 , 0.99475072, 0.99655022, 0.99791726, 0.99891386,\n",
       "       0.99947831, 0.99980557, 0.99996538, 1.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum((np.square(myPCA.s)))/np.sum((np.square(myPCA.s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>xAttack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010013</td>\n",
       "      <td>-0.034507</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.253425</td>\n",
       "      <td>0.071030</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.535332</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.362291</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.032512</td>\n",
       "      <td>-1.159545</td>\n",
       "      <td>-0.069609</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>2.878240</td>\n",
       "      <td>2.771138</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010023</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.382738</td>\n",
       "      <td>0.251048</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.729101</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761404</td>\n",
       "      <td>-0.647308</td>\n",
       "      <td>-0.228812</td>\n",
       "      <td>0.263823</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.594507</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.301658</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815626</td>\n",
       "      <td>-0.936833</td>\n",
       "      <td>-0.175745</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>1.610108</td>\n",
       "      <td>1.620205</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   service  src_bytes  dst_bytes       hot  num_failed_logins  \\\n",
       "0 -0.114538 -0.425936  -0.010013  -0.034507 -0.090956          -0.026322   \n",
       "1 -0.114538  0.362291  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "2 -0.114538 -0.425936  -0.010023   0.077316 -0.090956          -0.026322   \n",
       "3 -0.114538 -0.729101  -0.009539  -0.039819 -0.090956          -0.026322   \n",
       "4 -0.114538  0.301658  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files   ...     \\\n",
       "0        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "1        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "2        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "3        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "4        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "\n",
       "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0            1.262872                1.067572               -0.441083   \n",
       "1           -1.032512               -1.159545               -0.069609   \n",
       "2            1.262872                1.067572               -0.441083   \n",
       "3           -0.761404               -0.647308               -0.228812   \n",
       "4           -0.815626               -0.936833               -0.175745   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                    -0.253425                     0.071030   \n",
       "1                    -0.479722                    -0.289006   \n",
       "2                    -0.382738                     0.251048   \n",
       "3                     0.263823                    -0.289006   \n",
       "4                    -0.479722                    -0.289006   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0             -0.639500                 -0.535332             -0.386077   \n",
       "1             -0.639500                 -0.625146              2.878240   \n",
       "2             -0.639500                 -0.625146             -0.386077   \n",
       "3             -0.594507                 -0.625146             -0.386077   \n",
       "4              1.610108                  1.620205             -0.386077   \n",
       "\n",
       "   dst_host_srv_rerror_rate  xAttack  \n",
       "0                 -0.374982   normal  \n",
       "1                  2.771138      dos  \n",
       "2                 -0.374982   normal  \n",
       "3                 -0.374982   normal  \n",
       "4                 -0.374982      dos  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = myPCA.transform(df_standard[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>PCA_2</th>\n",
       "      <th>PCA_3</th>\n",
       "      <th>PCA_4</th>\n",
       "      <th>PCA_5</th>\n",
       "      <th>PCA_6</th>\n",
       "      <th>PCA_7</th>\n",
       "      <th>PCA_8</th>\n",
       "      <th>PCA_9</th>\n",
       "      <th>PCA_10</th>\n",
       "      <th>PCA_11</th>\n",
       "      <th>PCA_12</th>\n",
       "      <th>PCA_13</th>\n",
       "      <th>PCA_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.509465</td>\n",
       "      <td>0.952118</td>\n",
       "      <td>-0.080576</td>\n",
       "      <td>0.089474</td>\n",
       "      <td>-0.465568</td>\n",
       "      <td>0.264136</td>\n",
       "      <td>-0.073176</td>\n",
       "      <td>-0.122968</td>\n",
       "      <td>0.115930</td>\n",
       "      <td>-0.037055</td>\n",
       "      <td>-0.015486</td>\n",
       "      <td>-0.085031</td>\n",
       "      <td>-0.478762</td>\n",
       "      <td>0.380058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.193260</td>\n",
       "      <td>-5.598204</td>\n",
       "      <td>-0.270796</td>\n",
       "      <td>1.130964</td>\n",
       "      <td>-0.813104</td>\n",
       "      <td>1.629214</td>\n",
       "      <td>0.541853</td>\n",
       "      <td>0.190286</td>\n",
       "      <td>-0.243678</td>\n",
       "      <td>0.079392</td>\n",
       "      <td>0.028094</td>\n",
       "      <td>-0.064368</td>\n",
       "      <td>0.430118</td>\n",
       "      <td>0.264015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.447100</td>\n",
       "      <td>0.908940</td>\n",
       "      <td>-0.060319</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>-0.822739</td>\n",
       "      <td>0.170783</td>\n",
       "      <td>-0.098461</td>\n",
       "      <td>-0.161767</td>\n",
       "      <td>0.088160</td>\n",
       "      <td>0.084798</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>-0.050482</td>\n",
       "      <td>-0.754361</td>\n",
       "      <td>0.429615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.111758</td>\n",
       "      <td>0.343094</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>-0.266452</td>\n",
       "      <td>-0.166214</td>\n",
       "      <td>-0.596465</td>\n",
       "      <td>-0.015911</td>\n",
       "      <td>0.026994</td>\n",
       "      <td>-0.161913</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.050151</td>\n",
       "      <td>0.362929</td>\n",
       "      <td>-0.542295</td>\n",
       "      <td>0.408404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.983967</td>\n",
       "      <td>1.268863</td>\n",
       "      <td>-0.050828</td>\n",
       "      <td>0.252378</td>\n",
       "      <td>0.537147</td>\n",
       "      <td>0.561608</td>\n",
       "      <td>0.278506</td>\n",
       "      <td>0.038172</td>\n",
       "      <td>-0.012687</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>-0.013467</td>\n",
       "      <td>-0.041691</td>\n",
       "      <td>0.072667</td>\n",
       "      <td>-0.071333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PCA_1     PCA_2     PCA_3     PCA_4     PCA_5     PCA_6     PCA_7  \\\n",
       "0  2.509465  0.952118 -0.080576  0.089474 -0.465568  0.264136 -0.073176   \n",
       "1 -1.193260 -5.598204 -0.270796  1.130964 -0.813104  1.629214  0.541853   \n",
       "2  2.447100  0.908940 -0.060319  0.031070 -0.822739  0.170783 -0.098461   \n",
       "3  1.111758  0.343094  0.004162 -0.266452 -0.166214 -0.596465 -0.015911   \n",
       "4 -3.983967  1.268863 -0.050828  0.252378  0.537147  0.561608  0.278506   \n",
       "\n",
       "      PCA_8     PCA_9    PCA_10    PCA_11    PCA_12    PCA_13    PCA_14  \n",
       "0 -0.122968  0.115930 -0.037055 -0.015486 -0.085031 -0.478762  0.380058  \n",
       "1  0.190286 -0.243678  0.079392  0.028094 -0.064368  0.430118  0.264015  \n",
       "2 -0.161767  0.088160  0.084798  0.005995 -0.050482 -0.754361  0.429615  \n",
       "3  0.026994 -0.161913  0.061836  0.050151  0.362929 -0.542295  0.408404  \n",
       "4  0.038172 -0.012687  0.004357 -0.013467 -0.041691  0.072667 -0.071333  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "1. 14 Eigen Values correspond to 90% of the variance, i.e, 10% tolerance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=14, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=14)\n",
    "pca.fit(df_standard[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.509465</td>\n",
       "      <td>-0.952118</td>\n",
       "      <td>-0.080576</td>\n",
       "      <td>0.089474</td>\n",
       "      <td>-0.465568</td>\n",
       "      <td>-0.264136</td>\n",
       "      <td>-0.073176</td>\n",
       "      <td>0.122968</td>\n",
       "      <td>0.115930</td>\n",
       "      <td>-0.037055</td>\n",
       "      <td>0.015486</td>\n",
       "      <td>0.085031</td>\n",
       "      <td>0.478762</td>\n",
       "      <td>-0.380058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.193260</td>\n",
       "      <td>5.598204</td>\n",
       "      <td>-0.270796</td>\n",
       "      <td>1.130964</td>\n",
       "      <td>-0.813104</td>\n",
       "      <td>-1.629214</td>\n",
       "      <td>0.541853</td>\n",
       "      <td>-0.190286</td>\n",
       "      <td>-0.243678</td>\n",
       "      <td>0.079392</td>\n",
       "      <td>-0.028094</td>\n",
       "      <td>0.064368</td>\n",
       "      <td>-0.430118</td>\n",
       "      <td>-0.264015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.447100</td>\n",
       "      <td>-0.908940</td>\n",
       "      <td>-0.060319</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>-0.822739</td>\n",
       "      <td>-0.170783</td>\n",
       "      <td>-0.098461</td>\n",
       "      <td>0.161767</td>\n",
       "      <td>0.088160</td>\n",
       "      <td>0.084798</td>\n",
       "      <td>-0.005995</td>\n",
       "      <td>0.050482</td>\n",
       "      <td>0.754361</td>\n",
       "      <td>-0.429615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.111758</td>\n",
       "      <td>-0.343094</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>-0.266452</td>\n",
       "      <td>-0.166214</td>\n",
       "      <td>0.596465</td>\n",
       "      <td>-0.015911</td>\n",
       "      <td>-0.026994</td>\n",
       "      <td>-0.161913</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>-0.050151</td>\n",
       "      <td>-0.362929</td>\n",
       "      <td>0.542295</td>\n",
       "      <td>-0.408404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.983967</td>\n",
       "      <td>-1.268863</td>\n",
       "      <td>-0.050828</td>\n",
       "      <td>0.252378</td>\n",
       "      <td>0.537147</td>\n",
       "      <td>-0.561608</td>\n",
       "      <td>0.278506</td>\n",
       "      <td>-0.038172</td>\n",
       "      <td>-0.012687</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.013467</td>\n",
       "      <td>0.041691</td>\n",
       "      <td>-0.072667</td>\n",
       "      <td>0.071333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -2.509465 -0.952118 -0.080576  0.089474 -0.465568 -0.264136 -0.073176   \n",
       "1  1.193260  5.598204 -0.270796  1.130964 -0.813104 -1.629214  0.541853   \n",
       "2 -2.447100 -0.908940 -0.060319  0.031070 -0.822739 -0.170783 -0.098461   \n",
       "3 -1.111758 -0.343094  0.004162 -0.266452 -0.166214  0.596465 -0.015911   \n",
       "4  3.983967 -1.268863 -0.050828  0.252378  0.537147 -0.561608  0.278506   \n",
       "\n",
       "         7         8         9         10        11        12        13  \n",
       "0  0.122968  0.115930 -0.037055  0.015486  0.085031  0.478762 -0.380058  \n",
       "1 -0.190286 -0.243678  0.079392 -0.028094  0.064368 -0.430118 -0.264015  \n",
       "2  0.161767  0.088160  0.084798 -0.005995  0.050482  0.754361 -0.429615  \n",
       "3 -0.026994 -0.161913  0.061836 -0.050151 -0.362929  0.542295 -0.408404  \n",
       "4 -0.038172 -0.012687  0.004357  0.013467  0.041691 -0.072667  0.071333  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(pca.transform(df_standard[features]))\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23233278 0.16771547 0.09010134 0.06510947 0.05077007 0.04635866\n",
      " 0.03920077 0.03641207 0.03469033 0.03440369 0.03320159 0.03168948\n",
      " 0.02472306 0.02261023]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9093190252147921"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for Test Train split\n",
    "def splitData(X ,Y, test_size = 0.2, random_state = 10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = test_size ,random_state = random_state)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spltting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = splitData(df_transformed, df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_transformed\n",
    "y_train = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPurity(n_clusters, y_pred , y):\n",
    "    labels_ = {}\n",
    "    y_pred = np.array(y_pred)\n",
    "    y = np.array(y)\n",
    "    for i in range(n_clusters):\n",
    "        lst = list(y[y_pred == i])\n",
    "        labels_[i]  = max(set(lst), key=lst.count)\n",
    "    purity = {}\n",
    "    for i in range(n_clusters):\n",
    "        temp = y_pred[y_pred == i]\n",
    "        temp = np.array([labels_[i] for i in temp])\n",
    "        y1 = y[y_pred == i]\n",
    "        purity[i] = len(temp[temp == y1])/len(temp)\n",
    "    return (labels_, purity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART - 2 My K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKmeans():\n",
    "    def __init__(self, n_clusters = 3, random_state = 0, max_iter=300, tol=0.0001):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.random_state = random_state\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "    \n",
    "    def fit(self, df, y):\n",
    "        np_df = df.values\n",
    "        y = y.values\n",
    "        self.cols = df.columns.values\n",
    "        self.centers = {}\n",
    "        temp = random.sample(range(df.shape[0]),self.n_clusters)\n",
    "        for i in range(len(temp)):\n",
    "            self.centers[i] = np_df[temp[i]]\n",
    "        for i in range(self.max_iter):\n",
    "            self.classes = {}\n",
    "            self.indexes = {}\n",
    "            prev_centers = dict(self.centers)\n",
    "            for t in range(self.n_clusters):\n",
    "                self.classes[t] = []\n",
    "                self.indexes[t] = []\n",
    "            start = 0\n",
    "            for row in np_df:\n",
    "                dists = [np.linalg.norm(row-self.centers[c]) for c in self.centers]\n",
    "                index = dists.index(min(dists))\n",
    "                self.classes[index].append(row)\n",
    "                self.indexes[index].append(start)\n",
    "                start += 1\n",
    "            for t in range(len(self.centers)):\n",
    "                self.centers[t] = np.average(self.classes[t], axis = 0)\n",
    "            flag = True\n",
    "            error = 0.00\n",
    "            for t in range(len(self.centers)):\n",
    "                e = np.linalg.norm(prev_centers[t]-self.centers[t])\n",
    "                error += e\n",
    "                if(e > self.tol):\n",
    "                    flag = False\n",
    "            print(\"Iteration: {0}\".format(i))\n",
    "            print(\"Error: {0}\".format(float(error)))\n",
    "            if(flag):\n",
    "                break\n",
    "        self.labels_ = {}\n",
    "        for t in range(self.n_clusters):\n",
    "            lst = list(y[self.indexes[t]])\n",
    "            self.labels_[t] = max(set(lst), key=lst.count)\n",
    "        self.purity = {}\n",
    "        for t in range(self.n_clusters):\n",
    "            self.purity[t] = len(y[self.indexes[t]][y[self.indexes[t]] == self.labels_[t]])/len(self.classes[t])\n",
    "    \n",
    "    def predict_row(self, row):\n",
    "        dists = [np.linalg.norm(row-self.centers[c]) for c in self.centers]\n",
    "        index = dists.index(min(dists))\n",
    "        return index\n",
    "        \n",
    "    def predict(self, df):\n",
    "        res = []\n",
    "        for row in df.values:\n",
    "            res.append(self.predict_row(row))\n",
    "        return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MyKmeans(5, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Error: 8.593157962338001\n",
      "Iteration: 1\n",
      "Error: 5.238195341864797\n",
      "Iteration: 2\n",
      "Error: 2.5874322251436856\n",
      "Iteration: 3\n",
      "Error: 1.5865378269235066\n",
      "Iteration: 4\n",
      "Error: 0.8561211580097641\n",
      "Iteration: 5\n",
      "Error: 0.26836809620921254\n",
      "Iteration: 6\n",
      "Error: 0.058260000375898124\n",
      "Iteration: 7\n",
      "Error: 0.0046401395723837426\n",
      "Iteration: 8\n",
      "Error: 0.0030050654731510933\n",
      "Iteration: 9\n",
      "Error: 0.0\n"
     ]
    }
   ],
   "source": [
    "kmeans.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pred = kmeans.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, ..., 2, 3, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'dos', 1: 'dos', 2: 'normal', 3: 'normal', 4: 'normal'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans Purity:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({0: 'dos', 1: 'dos', 2: 'normal', 3: 'normal', 4: 'normal'},\n",
       " {0: 0.4623728813559322,\n",
       "  1: 0.9839525805985254,\n",
       "  2: 0.9193050533556751,\n",
       "  3: 0.5297587131367292,\n",
       "  4: 0.7244421380384016})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"KMeans Purity:\")\n",
    "calcPurity(5, kmeans_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn K means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans1 = KMeans(n_clusters=5, random_state=0).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_kmeans_pred = kmeans1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'probe', 1: 'normal', 2: 'dos', 3: 'dos', 4: 'normal'},\n",
       " {0: 0.8070866141732284,\n",
       "  1: 0.8974595515185921,\n",
       "  2: 0.9838126896950427,\n",
       "  3: 0.4603442456969288,\n",
       "  4: 1.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcPurity(5, sk_kmeans_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART - 3 GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imshow\n",
    "from sklearn import mixture\n",
    "gmm = mixture.GaussianMixture(covariance_type='full', n_components=5)\n",
    "gmm.fit(X_train)\n",
    "gmm_pred = gmm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 4 ... 3 4 1]\n"
     ]
    }
   ],
   "source": [
    "print(gmm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'normal', 1: 'dos', 2: 'normal', 3: 'normal', 4: 'normal'},\n",
       " {0: 0.49483985765124555,\n",
       "  1: 1.0,\n",
       "  2: 1.0,\n",
       "  3: 0.4834193072955048,\n",
       "  4: 0.8628218510786361})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcPurity(5, gmm_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART - 4 Hierarchical clustering with single-linkage and five clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='single')  \n",
    "hclust_pred = cluster.fit_predict(X_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'normal', 1: 'probe', 2: 'r2l', 3: 'normal', 4: 'normal'},\n",
       " {0: 0.5346352395053824, 1: 1.0, 2: 0.6666666666666666, 3: 1.0, 4: 1.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcPurity(5, hclust_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_types = {\"kmeans\" : kmeans_pred, \"gmm\" : gmm_pred, \"hclust\" : hclust_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_index = 0\n",
    "for cluster_type, y_pred in cluster_types.items():\n",
    "    labels, purity = calcPurity(5, y_pred, y_train)\n",
    "    labels = [\"cluster_\" + str(k) + \"_\" + val for k, val in labels.items()]\n",
    "    sizes = [val for k, val in purity.items()]\n",
    "    # print(sizes) # adds up to 1433, which is the total number of participants\n",
    "    ax1 = plt.subplot(2,2,plot_index+1)\n",
    "    ax1.figure.set_size_inches(20, 8)\n",
    "#     ax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True)\n",
    "    plt.bar(labels, sizes, align='center', alpha=0.5)\n",
    "    ax1.axis('equal')\n",
    "    ax1.set_title(str(cluster_type))\n",
    "    plot_index += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5\n",
    "Yes, PCA can be used with categorical variables, but it might/might not be effective based on the type of data.\n",
    "\n",
    "### Following things can be done for dimentionality reduction with Ordinal/Binary features :\n",
    "1. Consider ordinal features as numerical features.\n",
    "2. Use the polychoric correlation matrix (polychoric PCA).\n",
    "3. use means of a truncated distribution for variable scores.\n",
    "\n",
    "### PCA for Nominal data:\n",
    "1. Bucketing data and then applying the above methods\n",
    "2. Encoding the data into distinct numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_orig_df = pd.read_csv(\"AdmissionDataset/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242</td>\n",
       "      <td>317</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>334</td>\n",
       "      <td>319</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>326</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>232</td>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0         242        317          103                  2  2.5   2.0  8.15   \n",
       "1         334        319          108                  3  3.0   3.5  8.54   \n",
       "2           4        322          110                  3  3.5   2.5  8.67   \n",
       "3          45        326          113                  5  4.5   4.0  9.40   \n",
       "4         232        319          106                  3  3.5   2.5  8.33   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         0              0.65  \n",
       "1         1              0.71  \n",
       "2         1              0.80  \n",
       "3         1              0.91  \n",
       "4         1              0.74  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_orig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>247.726667</td>\n",
       "      <td>316.542222</td>\n",
       "      <td>107.162222</td>\n",
       "      <td>3.126667</td>\n",
       "      <td>3.361111</td>\n",
       "      <td>3.468889</td>\n",
       "      <td>8.577600</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.720889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.927656</td>\n",
       "      <td>11.335705</td>\n",
       "      <td>6.023554</td>\n",
       "      <td>1.140254</td>\n",
       "      <td>0.993374</td>\n",
       "      <td>0.919432</td>\n",
       "      <td>0.599454</td>\n",
       "      <td>0.497701</td>\n",
       "      <td>0.141398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>124.250000</td>\n",
       "      <td>308.250000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.122500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>246.500000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>373.750000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Serial No.   GRE Score  TOEFL Score  University Rating         SOP  \\\n",
       "count  450.000000  450.000000   450.000000         450.000000  450.000000   \n",
       "mean   247.726667  316.542222   107.162222           3.126667    3.361111   \n",
       "std    144.927656   11.335705     6.023554           1.140254    0.993374   \n",
       "min      1.000000  290.000000    92.000000           1.000000    1.000000   \n",
       "25%    124.250000  308.250000   103.000000           2.000000    2.500000   \n",
       "50%    246.500000  317.000000   107.000000           3.000000    3.500000   \n",
       "75%    373.750000  325.000000   112.000000           4.000000    4.000000   \n",
       "max    500.000000  340.000000   120.000000           5.000000    5.000000   \n",
       "\n",
       "             LOR         CGPA    Research  Chance of Admit   \n",
       "count  450.000000  450.000000  450.000000        450.000000  \n",
       "mean     3.468889    8.577600    0.553333          0.720889  \n",
       "std      0.919432    0.599454    0.497701          0.141398  \n",
       "min      1.000000    7.200000    0.000000          0.340000  \n",
       "25%      3.000000    8.122500    0.000000          0.630000  \n",
       "50%      3.500000    8.560000    1.000000          0.720000  \n",
       "75%      4.000000    9.040000    1.000000          0.820000  \n",
       "max      5.000000    9.920000    1.000000          0.970000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_orig_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_orig_cols = ['Serial_No', 'GRE_Score', 'TOEFL_Score', 'University_Rating', 'SOP', 'LOR', 'CGPA', 'Research', 'Chance_of_Admit']\n",
    "admission_orig_df.columns = admission_orig_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial_No</th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242</td>\n",
       "      <td>317</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>334</td>\n",
       "      <td>319</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>326</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>232</td>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial_No  GRE_Score  TOEFL_Score  University_Rating  SOP  LOR  CGPA  \\\n",
       "0        242        317          103                  2  2.5  2.0  8.15   \n",
       "1        334        319          108                  3  3.0  3.5  8.54   \n",
       "2          4        322          110                  3  3.5  2.5  8.67   \n",
       "3         45        326          113                  5  4.5  4.0  9.40   \n",
       "4        232        319          106                  3  3.5  2.5  8.33   \n",
       "\n",
       "   Research  Chance_of_Admit  \n",
       "0         0             0.65  \n",
       "1         1             0.71  \n",
       "2         1             0.80  \n",
       "3         1             0.91  \n",
       "4         1             0.74  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_orig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial_No</th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Serial_No, GRE_Score, TOEFL_Score, University_Rating, SOP, LOR, CGPA, Research, Chance_of_Admit]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_orig_df[admission_orig_df['GRE_Score'] != admission_orig_df.GRE_Score.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial_No</th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Serial_No</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.080196</td>\n",
       "      <td>-0.115323</td>\n",
       "      <td>-0.027499</td>\n",
       "      <td>-0.108152</td>\n",
       "      <td>0.010717</td>\n",
       "      <td>-0.061309</td>\n",
       "      <td>0.010068</td>\n",
       "      <td>0.023551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRE_Score</th>\n",
       "      <td>-0.080196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821423</td>\n",
       "      <td>0.631178</td>\n",
       "      <td>0.616670</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.826544</td>\n",
       "      <td>0.562533</td>\n",
       "      <td>0.810894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <td>-0.115323</td>\n",
       "      <td>0.821423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.642612</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.544411</td>\n",
       "      <td>0.810381</td>\n",
       "      <td>0.471452</td>\n",
       "      <td>0.790005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University_Rating</th>\n",
       "      <td>-0.027499</td>\n",
       "      <td>0.631178</td>\n",
       "      <td>0.642612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722434</td>\n",
       "      <td>0.614527</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.437424</td>\n",
       "      <td>0.685563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>-0.108152</td>\n",
       "      <td>0.616670</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.722434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.664015</td>\n",
       "      <td>0.713633</td>\n",
       "      <td>0.403552</td>\n",
       "      <td>0.681585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>0.010717</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.544411</td>\n",
       "      <td>0.614527</td>\n",
       "      <td>0.664015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640347</td>\n",
       "      <td>0.392998</td>\n",
       "      <td>0.644693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>-0.061309</td>\n",
       "      <td>0.826544</td>\n",
       "      <td>0.810381</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.713633</td>\n",
       "      <td>0.640347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.507005</td>\n",
       "      <td>0.877802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>0.010068</td>\n",
       "      <td>0.562533</td>\n",
       "      <td>0.471452</td>\n",
       "      <td>0.437424</td>\n",
       "      <td>0.403552</td>\n",
       "      <td>0.392998</td>\n",
       "      <td>0.507005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance_of_Admit</th>\n",
       "      <td>0.023551</td>\n",
       "      <td>0.810894</td>\n",
       "      <td>0.790005</td>\n",
       "      <td>0.685563</td>\n",
       "      <td>0.681585</td>\n",
       "      <td>0.644693</td>\n",
       "      <td>0.877802</td>\n",
       "      <td>0.557906</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Serial_No  GRE_Score  TOEFL_Score  University_Rating  \\\n",
       "Serial_No           1.000000  -0.080196    -0.115323          -0.027499   \n",
       "GRE_Score          -0.080196   1.000000     0.821423           0.631178   \n",
       "TOEFL_Score        -0.115323   0.821423     1.000000           0.642612   \n",
       "University_Rating  -0.027499   0.631178     0.642612           1.000000   \n",
       "SOP                -0.108152   0.616670     0.648256           0.722434   \n",
       "LOR                 0.010717   0.535315     0.544411           0.614527   \n",
       "CGPA               -0.061309   0.826544     0.810381           0.696721   \n",
       "Research            0.010068   0.562533     0.471452           0.437424   \n",
       "Chance_of_Admit     0.023551   0.810894     0.790005           0.685563   \n",
       "\n",
       "                        SOP       LOR      CGPA  Research  Chance_of_Admit  \n",
       "Serial_No         -0.108152  0.010717 -0.061309  0.010068         0.023551  \n",
       "GRE_Score          0.616670  0.535315  0.826544  0.562533         0.810894  \n",
       "TOEFL_Score        0.648256  0.544411  0.810381  0.471452         0.790005  \n",
       "University_Rating  0.722434  0.614527  0.696721  0.437424         0.685563  \n",
       "SOP                1.000000  0.664015  0.713633  0.403552         0.681585  \n",
       "LOR                0.664015  1.000000  0.640347  0.392998         0.644693  \n",
       "CGPA               0.713633  0.640347  1.000000  0.507005         0.877802  \n",
       "Research           0.403552  0.392998  0.507005  1.000000         0.557906  \n",
       "Chance_of_Admit    0.681585  0.644693  0.877802  0.557906         1.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = admission_orig_df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Serial Number\n",
    "admission_df = admission_orig_df.drop(columns=['Serial_No'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRE_Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821423</td>\n",
       "      <td>0.631178</td>\n",
       "      <td>0.616670</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.826544</td>\n",
       "      <td>0.562533</td>\n",
       "      <td>0.810894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <td>0.821423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.642612</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.544411</td>\n",
       "      <td>0.810381</td>\n",
       "      <td>0.471452</td>\n",
       "      <td>0.790005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University_Rating</th>\n",
       "      <td>0.631178</td>\n",
       "      <td>0.642612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722434</td>\n",
       "      <td>0.614527</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.437424</td>\n",
       "      <td>0.685563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>0.616670</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.722434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.664015</td>\n",
       "      <td>0.713633</td>\n",
       "      <td>0.403552</td>\n",
       "      <td>0.681585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.544411</td>\n",
       "      <td>0.614527</td>\n",
       "      <td>0.664015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640347</td>\n",
       "      <td>0.392998</td>\n",
       "      <td>0.644693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>0.826544</td>\n",
       "      <td>0.810381</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.713633</td>\n",
       "      <td>0.640347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.507005</td>\n",
       "      <td>0.877802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>0.562533</td>\n",
       "      <td>0.471452</td>\n",
       "      <td>0.437424</td>\n",
       "      <td>0.403552</td>\n",
       "      <td>0.392998</td>\n",
       "      <td>0.507005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance_of_Admit</th>\n",
       "      <td>0.810894</td>\n",
       "      <td>0.790005</td>\n",
       "      <td>0.685563</td>\n",
       "      <td>0.681585</td>\n",
       "      <td>0.644693</td>\n",
       "      <td>0.877802</td>\n",
       "      <td>0.557906</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   GRE_Score  TOEFL_Score  University_Rating       SOP  \\\n",
       "GRE_Score           1.000000     0.821423           0.631178  0.616670   \n",
       "TOEFL_Score         0.821423     1.000000           0.642612  0.648256   \n",
       "University_Rating   0.631178     0.642612           1.000000  0.722434   \n",
       "SOP                 0.616670     0.648256           0.722434  1.000000   \n",
       "LOR                 0.535315     0.544411           0.614527  0.664015   \n",
       "CGPA                0.826544     0.810381           0.696721  0.713633   \n",
       "Research            0.562533     0.471452           0.437424  0.403552   \n",
       "Chance_of_Admit     0.810894     0.790005           0.685563  0.681585   \n",
       "\n",
       "                        LOR      CGPA  Research  Chance_of_Admit  \n",
       "GRE_Score          0.535315  0.826544  0.562533         0.810894  \n",
       "TOEFL_Score        0.544411  0.810381  0.471452         0.790005  \n",
       "University_Rating  0.614527  0.696721  0.437424         0.685563  \n",
       "SOP                0.664015  0.713633  0.403552         0.681585  \n",
       "LOR                1.000000  0.640347  0.392998         0.644693  \n",
       "CGPA               0.640347  1.000000  0.507005         0.877802  \n",
       "Research           0.392998  0.507005  1.000000         0.557906  \n",
       "Chance_of_Admit    0.644693  0.877802  0.557906         1.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = admission_df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe09d474128>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the heatmap\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#admission_df.iloc[:,admission_df.columns != 'Chance_of_Admit'] = (admission_df.iloc[:,admission_df.columns != 'Chance_of_Admit'] - admission_df.iloc[:,admission_df.columns != 'Chance_of_Admit'].mean())/admission_df.iloc[:,admission_df.columns != 'Chance_of_Admit'].std()\n",
    "# admission_df = (admission_df - admission_df.mean())/admission_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>316.542222</td>\n",
       "      <td>107.162222</td>\n",
       "      <td>3.126667</td>\n",
       "      <td>3.361111</td>\n",
       "      <td>3.468889</td>\n",
       "      <td>8.577600</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.720889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.335705</td>\n",
       "      <td>6.023554</td>\n",
       "      <td>1.140254</td>\n",
       "      <td>0.993374</td>\n",
       "      <td>0.919432</td>\n",
       "      <td>0.599454</td>\n",
       "      <td>0.497701</td>\n",
       "      <td>0.141398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>308.250000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.122500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GRE_Score  TOEFL_Score  University_Rating         SOP         LOR  \\\n",
       "count  450.000000   450.000000         450.000000  450.000000  450.000000   \n",
       "mean   316.542222   107.162222           3.126667    3.361111    3.468889   \n",
       "std     11.335705     6.023554           1.140254    0.993374    0.919432   \n",
       "min    290.000000    92.000000           1.000000    1.000000    1.000000   \n",
       "25%    308.250000   103.000000           2.000000    2.500000    3.000000   \n",
       "50%    317.000000   107.000000           3.000000    3.500000    3.500000   \n",
       "75%    325.000000   112.000000           4.000000    4.000000    4.000000   \n",
       "max    340.000000   120.000000           5.000000    5.000000    5.000000   \n",
       "\n",
       "             CGPA    Research  Chance_of_Admit  \n",
       "count  450.000000  450.000000       450.000000  \n",
       "mean     8.577600    0.553333         0.720889  \n",
       "std      0.599454    0.497701         0.141398  \n",
       "min      7.200000    0.000000         0.340000  \n",
       "25%      8.122500    0.000000         0.630000  \n",
       "50%      8.560000    1.000000         0.720000  \n",
       "75%      9.040000    1.000000         0.820000  \n",
       "max      9.920000    1.000000         0.970000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into train(80%) and validation(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_train_X, admission_val_X, admission_train_Y, admission_val_Y = splitData(admission_df.iloc[:,admission_df.columns != 'Chance_of_Admit'], admission_df['Chance_of_Admit'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(row1, row2):\n",
    "    if(len(row1) != len(row2)):\n",
    "        raise ValueError('row lengths do not match in euclidean dist calculation!')\n",
    "    return np.sqrt(np.sum([(x-y)**2 for x, y in zip(row1,row2)]))\n",
    "\n",
    "def chebyshev(row1, row2):\n",
    "    if(len(row1) != len(row2)):\n",
    "        raise ValueError('row lengths do not match in chebyshev dist calculation!')\n",
    "    return np.max([abs(x-y) for x, y in zip(row1,row2)])\n",
    "\n",
    "def manhattan(row1, row2):\n",
    "    if(len(row1) != len(row2)):\n",
    "        raise ValueError('row lengths do not match in manhattan dist calculation!')\n",
    "    return np.sum([abs(x-y) for x, y in zip(row1,row2)])\n",
    "\n",
    "def minkowski(row1, row2):\n",
    "    if(len(row1) != len(row2)):\n",
    "        raise ValueError('row lengths do not match in minkowski dist calculation!')\n",
    "    x = np.cbrt(np.sum([abs(x-y)**3 for x, y in zip(row1,row2)]))\n",
    "#     print(x)\n",
    "    return x\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def printRegressionErrors(y, y_pred):\n",
    "    mse = metrics.mean_squared_error(sigmoid(admission_val_Y), y_pred)  \n",
    "    mae = metrics.mean_absolute_error(sigmoid(admission_val_Y), y_pred)\n",
    "    mape = mean_absolute_percentage_error(sigmoid(admission_val_Y), y_pred)\n",
    "    print(\"MSE : {0}\".format(mse))\n",
    "    print(\"MAE : {0}\".format(mae))\n",
    "    print(\"MAPE : {0}\".format(mape))\n",
    "    \n",
    "def makeCoeffDF(coeffs):\n",
    "    coeff_cols = ['GRE_Score', 'TOEFL_Score', \n",
    "                  'University_Rating', 'SOP', 'LOR', 'CGPA', 'Research', 'Intercept']\n",
    "    coeff_df = pd.DataFrame(coeffs, columns=coeff_cols)\n",
    "    return coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(Y_predict, Y_test):\n",
    "    accuracy = metrics.accuracy_score(Y_test, Y_predict)\n",
    "    precision = metrics.precision_score(Y_test, Y_predict, pos_label=1, average='macro')\n",
    "    recall = metrics.recall_score(Y_test, Y_predict,pos_label=1, average='macro')\n",
    "    f1_score = metrics.f1_score(Y_test, Y_predict,pos_label=1, average='macro')\n",
    "    print(\"Accuracy : \" +str(accuracy))\n",
    "    print(\"Precision : \" +str(precision))\n",
    "    print(\"recall : \" +str(recall))\n",
    "    print(\"f1 Score : \" +str(f1_score))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(Y_predict, Y_test):\n",
    "    accuracy = metrics.accuracy_score(Y_test, Y_predict)\n",
    "    precision = metrics.precision_score(Y_test, Y_predict, pos_label=1, average='macro')\n",
    "    recall = metrics.recall_score(Y_test, Y_predict,pos_label=1, average='macro')\n",
    "    f1_score = metrics.f1_score(Y_test, Y_predict,pos_label=1, average='macro')\n",
    "    return [accuracy, precision, recall, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating metrics for all datasets\n",
    "def evaluate_metric_dataframe(datasets1, model):\n",
    "    metric_cols = ['DataSet', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "    metric_df = pd.DataFrame(columns = metric_cols)\n",
    "    for data in datasets1:\n",
    "        model.fit(data[1], data[2])\n",
    "        pred_Y = model.predict(data[3])\n",
    "        scores = calc_metrics(pred_Y, data[4])\n",
    "        metric_df = metric_df.append(pd.DataFrame([[data[0]] + scores], columns=metric_cols),ignore_index=True)\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, n_neighbors=5, metric=euclidean):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.metric = metric\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler = self.scaler.fit(X)\n",
    "        self.train_X = pd.DataFrame(self.scaler.transform(X), columns=X.columns)\n",
    "#         self.train_X = X\n",
    "        self.train_Y = Y\n",
    "\n",
    "    def scalerFit(self, df):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df)\n",
    "        return scaler\n",
    "\n",
    "    def transform(self, scalar, df, cols):\n",
    "        df_scaled = pd.DataFrame(scaler.transform(df[cols]), columns=cols)\n",
    "        return df_scaled\n",
    "\n",
    "    def predict_row(self, row):\n",
    "        dists = []\n",
    "        index = 0\n",
    "        for i, train_row in self.train_X.iterrows():\n",
    "            dist = self.metric(row, train_row)\n",
    "            label = self.train_Y.iloc[index]\n",
    "            dists.append((dist,label))\n",
    "            index += 1\n",
    "        dists.sort()\n",
    "        dists = dists[:self.n_neighbors]\n",
    "        elem,count = np.unique([j for (i,j) in dists], return_counts=True)\n",
    "        return elem[np.argmax(count)]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(self.scaler.transform(X), columns=X.columns)\n",
    "        y = []\n",
    "        for index, row in X.iterrows():\n",
    "            y.append(self.predict_row(row))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART - 1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_df_log = admission_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>326</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE_Score  TOEFL_Score  University_Rating  SOP  LOR  CGPA  Research  \\\n",
       "0        317          103                  2  2.5  2.0  8.15         0   \n",
       "1        319          108                  3  3.0  3.5  8.54         1   \n",
       "2        322          110                  3  3.5  2.5  8.67         1   \n",
       "3        326          113                  5  4.5  4.0  9.40         1   \n",
       "4        319          106                  3  3.5  2.5  8.33         1   \n",
       "\n",
       "   Chance_of_Admit  \n",
       "0             0.65  \n",
       "1             0.71  \n",
       "2             0.80  \n",
       "3             0.91  \n",
       "4             0.74  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_df_log['Chance_of_Admit'] = [1 if x >= 0.5 else 0 for x in admission_df['Chance_of_Admit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>316.542222</td>\n",
       "      <td>107.162222</td>\n",
       "      <td>3.126667</td>\n",
       "      <td>3.361111</td>\n",
       "      <td>3.468889</td>\n",
       "      <td>8.577600</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.922222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.335705</td>\n",
       "      <td>6.023554</td>\n",
       "      <td>1.140254</td>\n",
       "      <td>0.993374</td>\n",
       "      <td>0.919432</td>\n",
       "      <td>0.599454</td>\n",
       "      <td>0.497701</td>\n",
       "      <td>0.268120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>308.250000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.122500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GRE_Score  TOEFL_Score  University_Rating         SOP         LOR  \\\n",
       "count  450.000000   450.000000         450.000000  450.000000  450.000000   \n",
       "mean   316.542222   107.162222           3.126667    3.361111    3.468889   \n",
       "std     11.335705     6.023554           1.140254    0.993374    0.919432   \n",
       "min    290.000000    92.000000           1.000000    1.000000    1.000000   \n",
       "25%    308.250000   103.000000           2.000000    2.500000    3.000000   \n",
       "50%    317.000000   107.000000           3.000000    3.500000    3.500000   \n",
       "75%    325.000000   112.000000           4.000000    4.000000    4.000000   \n",
       "max    340.000000   120.000000           5.000000    5.000000    5.000000   \n",
       "\n",
       "             CGPA    Research  Chance_of_Admit  \n",
       "count  450.000000  450.000000       450.000000  \n",
       "mean     8.577600    0.553333         0.922222  \n",
       "std      0.599454    0.497701         0.268120  \n",
       "min      7.200000    0.000000         0.000000  \n",
       "25%      8.122500    0.000000         1.000000  \n",
       "50%      8.560000    1.000000         1.000000  \n",
       "75%      9.040000    1.000000         1.000000  \n",
       "max      9.920000    1.000000         1.000000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_df_log.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_train_X, admission_val_X, admission_train_Y, admission_val_Y = splitData(admission_df_log.iloc[:,admission_df_log.columns != 'Chance_of_Admit'], admission_df_log['Chance_of_Admit'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegresson:\n",
    "    def __init__(self, learning_rate = 0.01, no_iterations = 1000 ,threshold = 0.5):\n",
    "        self.alpha = learning_rate\n",
    "        self.iterations = no_iterations\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def normalize_X(self, X):\n",
    "        X_normalized = (X - self.X_mean)/self.X_var\n",
    "        return X_normalized\n",
    "\n",
    "    def normalize_Y(self, Y):\n",
    "#         return X\n",
    "        Y_normalized = (Y - self.Y_mean)/self.Y_var\n",
    "        return Y_normalized\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        #### m = no of examples, n = no of features\n",
    "        ### X : shape = mxn\n",
    "        ### Y : shape = 1xm\n",
    "        self.X_mean = X.mean()\n",
    "#         print(\"mean: {0}\",self.X_mean)\n",
    "        self.X_var = X.std()\n",
    "        self.Y_mean = Y.mean()\n",
    "        self.Y_var = Y.std()\n",
    "        \n",
    "        X  = self.normalize_X(X)\n",
    "#         Y  = self.normalize_Y(Y)\n",
    "        c = np.ones((1, len(X)))  ### shape = 1xm\n",
    "        X_temp = np.concatenate((X, c.T), axis=1) ## Shape : mxn\n",
    "        theta = np.zeros((1, len(X_temp[0]))) ## shape: 1 X n \n",
    "        Y_temp = Y.values.reshape(len(X),1)  ## shape : (m,1)\n",
    "#         print(X_temp)\n",
    "#         print(\"X : {0}, theta : {1}, Y : {2}\".format(X_temp.shape, theta.shape, Y_temp.shape))\n",
    "        theta, cost_hist = self.gradient_descent(theta, X_temp, Y_temp, self.alpha, self.iterations)\n",
    "        self.theta = theta\n",
    "        self.coef_ = theta.flatten()[:-1]\n",
    "        self.cost_hist = cost_hist\n",
    "        self.intercept_ = theta.flatten()[-1:]\n",
    "#         print(theta)\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        X = self.normalize_X(X)\n",
    "        c = np.ones((1, len(X)))  ### shape = 1xm\n",
    "        X_temp = np.concatenate((X, c.T), axis=1) ## Shape : kxn\n",
    "        y_pred = np.dot(X_temp,self.theta.T)\n",
    "        return sigmoid(y_pred.flatten())\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_probs = self.predict_probs(X)\n",
    "        y_probs[y_probs >= self.threshold] = 1\n",
    "        y_probs[y_probs < self.threshold] = 0\n",
    "        return y_probs\n",
    "    \n",
    "    def allCoeffs(self):\n",
    "        coeffs = list(self.coef_) + list(self.intercept_)\n",
    "        coeffs = np.array(coeffs).reshape(1, len(coeffs))\n",
    "        return coeffs\n",
    "    \n",
    "    def __loss(self, Y, h):\n",
    "        h1 = h.copy()\n",
    "        h1[h1 == 0] = 1\n",
    "        h2 = h.copy()\n",
    "        h2[h2 == 1] = 0\n",
    "        return np.mean(-Y * np.log(h1) - (1 - Y) * np.log(1 - h2))\n",
    "        \n",
    "    def gradient_descent(self, theta, X, Y, alpha, iterations):\n",
    "        cost_history = [0] * iterations\n",
    "        m = len(Y)\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            # Hypothesis Values\n",
    "#             print(theta)\n",
    "#             print(X.shape, theta.T.shape)\n",
    "            zz = np.dot(X,theta.T)\n",
    "#             print(zz)\n",
    "            h = sigmoid(zz) ## shape : (m,1)\n",
    "            \n",
    "            loss = h - Y ## shape: (m,1)\n",
    "#             print(\"loss: {0}\".format(loss.shape))\n",
    "#             print(\"loss : {0}\".format(np.sum(loss)))\n",
    "            # Gradient Calculation\n",
    "            gradient = np.dot(X.T,loss) / m   ##shape : (n,1)\n",
    "#             print(\"grad: {0}\".format(gradient.shape))\n",
    "            # Changing Values of B using Gradient\n",
    "            theta = theta - alpha * (gradient.T)\n",
    "#             print(theta.shape)\n",
    "            # New Cost Value\n",
    "            cost = self.__loss(Y, h)\n",
    "            cost_history[iteration] = cost\n",
    "#             print(\"i: {0}\".format(iteration), sep=\" \")\n",
    "#             print(\"theta: {0}\".format(theta), sep= \" \")\n",
    "#             print(\"cost: {0}\".format(cost))\n",
    "#             print(cost, theta)\n",
    "        \n",
    "#         ax = plt.subplot(1,1,1)\n",
    "#         ax.plot(range(iterations), cost_history)\n",
    "#         ax.set_xlabel('iteration')\n",
    "#         ax.set_ylabel('cost')\n",
    "#         plt.show()\n",
    "\n",
    "        return theta, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "lr = MyLogisticRegresson(0.01, 10000)\n",
    "lr.fit(admission_train_X,admission_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(admission_val_X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.441141</td>\n",
       "      <td>0.754185</td>\n",
       "      <td>-0.255086</td>\n",
       "      <td>-0.467181</td>\n",
       "      <td>0.481577</td>\n",
       "      <td>1.356643</td>\n",
       "      <td>0.045651</td>\n",
       "      <td>3.947705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE_Score  TOEFL_Score  University_Rating       SOP       LOR      CGPA  \\\n",
       "0   0.441141     0.754185          -0.255086 -0.467181  0.481577  1.356643   \n",
       "\n",
       "   Research  Intercept  \n",
       "0  0.045651   3.947705  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeCoeffDF(lr.allCoeffs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(admission_val_Y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[-0.08908858  0.11668916  0.05232433 -0.2544266   0.75885504  2.04799802\n",
      "   0.6798165 ]]\n",
      "[-0.61218553]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(admission_train_X, admission_train_Y)\n",
    "y_pred = clf.predict(admission_val_X)\n",
    "print(y_pred)\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "metrics.accuracy_score(admission_val_Y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>327</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>320</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>320</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>309</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>338</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE_Score  TOEFL_Score  University_Rating  SOP  LOR  CGPA  Research\n",
       "66         327          111                  4  3.0  4.0  8.40         1\n",
       "309        320          110                  5  5.0  4.5  9.22         1\n",
       "312        320          112                  2  3.5  3.5  8.78         1\n",
       "12         309          105                  4  3.5  2.0  8.18         0\n",
       "219        338          118                  4  3.0  4.5  9.40         1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "myKNN = KNN(n_neighbors=5, metric=euclidean)\n",
    "myKNN.fit(admission_train_X, admission_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = myKNN.predict(admission_val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111111111111111"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(admission_val_Y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "1. Accuracy of the Logistic regression on the validation dataset is ~95% and the same for KNN is 91%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1_fin = 0\n",
    "f1_index = 0\n",
    "thresholds = [i/50 for i in range(0,50)]\n",
    "for threshold in thresholds:\n",
    "    lr = MyLogisticRegresson(0.1, 500, threshold)\n",
    "    lr.fit(admission_train_X,admission_train_Y)  \n",
    "    y_pred = lr.predict(admission_val_X)\n",
    "    precisions.append(metrics.precision_score(y_pred=y_pred, y_true=admission_val_Y))\n",
    "    recalls.append(metrics.recall_score(y_pred=y_pred, y_true=admission_val_Y))\n",
    "    f1 = metrics.f1_score(y_pred, admission_val_Y)\n",
    "    if(f1 > f1_fin):\n",
    "        f1_index = threshold\n",
    "        f1_fin = f1\n",
    "    \n",
    "ax = plt.subplot(2, 1, 1)\n",
    "# plt.style.use('seaborn-darkgrid')\n",
    "ax.figure.set_size_inches(10,15)\n",
    "\n",
    "# create a color palette\n",
    "palette = plt.get_cmap('Set1')\n",
    "ax.plot(thresholds, precisions, marker='', color=palette(0), linewidth=1, alpha=0.9, label='precision')\n",
    "ax.plot(thresholds, recalls, marker='', color=palette(1), linewidth=1, alpha=0.9, label='recall')\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc=2, ncol=2)\n",
    "\n",
    "# Add titles\n",
    "# ax.set_title(\"Precision and Recall variation\", loc='left', fontsize=12, fontweight=0, color='orange')\n",
    "ax.set_xlabel('threshold')\n",
    "ax.set_ylabel('metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "1. The best threshold would be where the F1 score is maximum, i.e 0.58 in this case, as we want both the precision as well as the recall to be good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df_orig = pd.read_csv(\"./wine-quality/data_changed.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.026</td>\n",
       "      <td>31.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99160</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.37</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.27</td>\n",
       "      <td>10.90</td>\n",
       "      <td>0.038</td>\n",
       "      <td>29.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.99496</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>16.65</td>\n",
       "      <td>0.044</td>\n",
       "      <td>39.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.99855</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.058</td>\n",
       "      <td>49.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.99790</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.47</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.037</td>\n",
       "      <td>42.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.99822</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2      3      4     5      6        7     8     9     10  11\n",
       "0  9.2  0.25  0.34   1.20  0.026  31.0   93.0  0.99160  2.93  0.37  11.3   7\n",
       "1  6.6  0.20  0.27  10.90  0.038  29.0  130.0  0.99496  3.11  0.44  10.5   7\n",
       "2  5.7  0.22  0.22  16.65  0.044  39.0  110.0  0.99855  3.24  0.48   9.0   6\n",
       "3  7.2  0.23  0.39  14.20  0.058  49.0  192.0  0.99790  2.98  0.48   9.0   7\n",
       "4  7.6  0.35  0.47  13.30  0.037  42.0  116.0  0.99822  3.04  0.50   9.2   5"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.852189</td>\n",
       "      <td>0.278565</td>\n",
       "      <td>0.333786</td>\n",
       "      <td>6.355377</td>\n",
       "      <td>0.045758</td>\n",
       "      <td>35.307849</td>\n",
       "      <td>138.007827</td>\n",
       "      <td>0.994001</td>\n",
       "      <td>3.187675</td>\n",
       "      <td>0.488185</td>\n",
       "      <td>10.513036</td>\n",
       "      <td>5.873866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.838939</td>\n",
       "      <td>0.100747</td>\n",
       "      <td>0.121491</td>\n",
       "      <td>4.981474</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>17.024667</td>\n",
       "      <td>41.854932</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.150323</td>\n",
       "      <td>0.113913</td>\n",
       "      <td>1.226730</td>\n",
       "      <td>0.882972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.991720</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.993700</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996040</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.542500</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.010300</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  4408.000000  4408.000000  4408.000000  4408.000000  4408.000000   \n",
       "mean      6.852189     0.278565     0.333786     6.355377     0.045758   \n",
       "std       0.838939     0.100747     0.121491     4.981474     0.022044   \n",
       "min       3.900000     0.080000     0.000000     0.600000     0.009000   \n",
       "25%       6.300000     0.210000     0.270000     1.700000     0.036000   \n",
       "50%       6.800000     0.260000     0.310000     5.200000     0.043000   \n",
       "75%       7.300000     0.320000     0.390000     9.800000     0.050000   \n",
       "max      14.200000     1.100000     1.660000    31.600000     0.346000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  4408.000000  4408.000000  4408.000000  4408.000000  4408.000000   \n",
       "mean     35.307849   138.007827     0.994001     3.187675     0.488185   \n",
       "std      17.024667    41.854932     0.002909     0.150323     0.113913   \n",
       "min       2.000000     9.000000     0.987110     2.720000     0.220000   \n",
       "25%      23.000000   108.000000     0.991720     3.090000     0.410000   \n",
       "50%      34.000000   134.000000     0.993700     3.180000     0.470000   \n",
       "75%      46.000000   167.000000     0.996040     3.280000     0.542500   \n",
       "max     289.000000   440.000000     1.010300     3.810000     1.080000   \n",
       "\n",
       "                10           11  \n",
       "count  4408.000000  4408.000000  \n",
       "mean     10.513036     5.873866  \n",
       "std       1.226730     0.882972  \n",
       "min       8.000000     3.000000  \n",
       "25%       9.500000     5.000000  \n",
       "50%      10.400000     6.000000  \n",
       "75%      11.400000     6.000000  \n",
       "max      14.200000     9.000000  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df_orig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df_orig.columns = df_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.026</td>\n",
       "      <td>31.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99160</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.37</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.27</td>\n",
       "      <td>10.90</td>\n",
       "      <td>0.038</td>\n",
       "      <td>29.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.99496</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>16.65</td>\n",
       "      <td>0.044</td>\n",
       "      <td>39.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.99855</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.058</td>\n",
       "      <td>49.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.99790</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.47</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.037</td>\n",
       "      <td>42.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.99822</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            9.2              0.25         0.34            1.20      0.026   \n",
       "1            6.6              0.20         0.27           10.90      0.038   \n",
       "2            5.7              0.22         0.22           16.65      0.044   \n",
       "3            7.2              0.23         0.39           14.20      0.058   \n",
       "4            7.6              0.35         0.47           13.30      0.037   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 31.0                  93.0  0.99160  2.93       0.37   \n",
       "1                 29.0                 130.0  0.99496  3.11       0.44   \n",
       "2                 39.0                 110.0  0.99855  3.24       0.48   \n",
       "3                 49.0                 192.0  0.99790  2.98       0.48   \n",
       "4                 42.0                 116.0  0.99822  3.04       0.50   \n",
       "\n",
       "   alcohol  quality  \n",
       "0     11.3        7  \n",
       "1     10.5        7  \n",
       "2      9.0        6  \n",
       "3      9.0        7  \n",
       "4      9.2        5  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.852189</td>\n",
       "      <td>0.278565</td>\n",
       "      <td>0.333786</td>\n",
       "      <td>6.355377</td>\n",
       "      <td>0.045758</td>\n",
       "      <td>35.307849</td>\n",
       "      <td>138.007827</td>\n",
       "      <td>0.994001</td>\n",
       "      <td>3.187675</td>\n",
       "      <td>0.488185</td>\n",
       "      <td>10.513036</td>\n",
       "      <td>5.873866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.838939</td>\n",
       "      <td>0.100747</td>\n",
       "      <td>0.121491</td>\n",
       "      <td>4.981474</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>17.024667</td>\n",
       "      <td>41.854932</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.150323</td>\n",
       "      <td>0.113913</td>\n",
       "      <td>1.226730</td>\n",
       "      <td>0.882972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.991720</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.993700</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996040</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.542500</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.010300</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed_acidity  volatile_acidity  citric_acid  residual_sugar  \\\n",
       "count    4408.000000       4408.000000  4408.000000     4408.000000   \n",
       "mean        6.852189          0.278565     0.333786        6.355377   \n",
       "std         0.838939          0.100747     0.121491        4.981474   \n",
       "min         3.900000          0.080000     0.000000        0.600000   \n",
       "25%         6.300000          0.210000     0.270000        1.700000   \n",
       "50%         6.800000          0.260000     0.310000        5.200000   \n",
       "75%         7.300000          0.320000     0.390000        9.800000   \n",
       "max        14.200000          1.100000     1.660000       31.600000   \n",
       "\n",
       "         chlorides  free_sulfur_dioxide  total_sulfur_dioxide      density  \\\n",
       "count  4408.000000          4408.000000           4408.000000  4408.000000   \n",
       "mean      0.045758            35.307849            138.007827     0.994001   \n",
       "std       0.022044            17.024667             41.854932     0.002909   \n",
       "min       0.009000             2.000000              9.000000     0.987110   \n",
       "25%       0.036000            23.000000            108.000000     0.991720   \n",
       "50%       0.043000            34.000000            134.000000     0.993700   \n",
       "75%       0.050000            46.000000            167.000000     0.996040   \n",
       "max       0.346000           289.000000            440.000000     1.010300   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  4408.000000  4408.000000  4408.000000  4408.000000  \n",
       "mean      3.187675     0.488185    10.513036     5.873866  \n",
       "std       0.150323     0.113913     1.226730     0.882972  \n",
       "min       2.720000     0.220000     8.000000     3.000000  \n",
       "25%       3.090000     0.410000     9.500000     5.000000  \n",
       "50%       3.180000     0.470000    10.400000     6.000000  \n",
       "75%       3.280000     0.542500    11.400000     6.000000  \n",
       "max       3.810000     1.080000    14.200000     9.000000  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df_orig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    1987\n",
       "5    1311\n",
       "7     785\n",
       "8     153\n",
       "4     150\n",
       "3      17\n",
       "9       5\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df_orig.quality.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_train_X, wine_val_X, wine_train_Y, wine_val_Y = splitData(wine_df_orig.iloc[:,wine_df_orig.columns != 'quality'], wine_df_orig['quality'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.855062</td>\n",
       "      <td>0.279546</td>\n",
       "      <td>0.334155</td>\n",
       "      <td>6.379594</td>\n",
       "      <td>0.045625</td>\n",
       "      <td>35.309558</td>\n",
       "      <td>138.342881</td>\n",
       "      <td>0.994001</td>\n",
       "      <td>3.188616</td>\n",
       "      <td>0.488213</td>\n",
       "      <td>10.527660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.837837</td>\n",
       "      <td>0.100915</td>\n",
       "      <td>0.121400</td>\n",
       "      <td>4.985762</td>\n",
       "      <td>0.022126</td>\n",
       "      <td>17.018437</td>\n",
       "      <td>42.086619</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.151248</td>\n",
       "      <td>0.113141</td>\n",
       "      <td>1.229251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.712500</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>0.991700</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.500000</td>\n",
       "      <td>0.993730</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.775000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996047</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.010300</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed_acidity  volatile_acidity  citric_acid  residual_sugar  \\\n",
       "count    3526.000000       3526.000000  3526.000000     3526.000000   \n",
       "mean        6.855062          0.279546     0.334155        6.379594   \n",
       "std         0.837837          0.100915     0.121400        4.985762   \n",
       "min         3.900000          0.080000     0.000000        0.600000   \n",
       "25%         6.300000          0.210000     0.270000        1.712500   \n",
       "50%         6.800000          0.260000     0.320000        5.200000   \n",
       "75%         7.300000          0.320000     0.390000        9.775000   \n",
       "max        14.200000          1.100000     1.660000       31.600000   \n",
       "\n",
       "         chlorides  free_sulfur_dioxide  total_sulfur_dioxide      density  \\\n",
       "count  3526.000000          3526.000000           3526.000000  3526.000000   \n",
       "mean      0.045625            35.309558            138.342881     0.994001   \n",
       "std       0.022126            17.018437             42.086619     0.002921   \n",
       "min       0.012000             2.000000             10.000000     0.987110   \n",
       "25%       0.035000            23.000000            109.000000     0.991700   \n",
       "50%       0.043000            34.000000            134.500000     0.993730   \n",
       "75%       0.050000            46.000000            167.000000     0.996047   \n",
       "max       0.346000           289.000000            440.000000     1.010300   \n",
       "\n",
       "                pH    sulphates      alcohol  \n",
       "count  3526.000000  3526.000000  3526.000000  \n",
       "mean      3.188616     0.488213    10.527660  \n",
       "std       0.151248     0.113141     1.229251  \n",
       "min       2.720000     0.250000     8.000000  \n",
       "25%       3.090000     0.410000     9.500000  \n",
       "50%       3.180000     0.470000    10.400000  \n",
       "75%       3.280000     0.550000    11.400000  \n",
       "max       3.810000     1.080000    14.050000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_train_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    1608\n",
       "5    1016\n",
       "7     641\n",
       "4     123\n",
       "8     122\n",
       "3      12\n",
       "9       4\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for class: 3\n",
      "Running for class: 4\n",
      "Running for class: 5\n",
      "Running for class: 6\n",
      "Running for class: 7\n",
      "Running for class: 8\n",
      "Running for class: 9\n"
     ]
    }
   ],
   "source": [
    "y_pred_final = np.array([0 for i in range(len(wine_val_Y))])\n",
    "y_pred_prob_final = np.array([0.00 for i in range(len(wine_val_Y))])\n",
    "for class_val in range(3,10):\n",
    "    print(\"Running for class: {0}\".format(class_val))\n",
    "    lr = MyLogisticRegresson(0.1, 500)\n",
    "    y_temp = wine_train_Y.copy()\n",
    "    y_temp[y_temp != class_val] = 0\n",
    "    y_temp[y_temp == class_val] = 1\n",
    "    y_val_temp = wine_val_Y.copy()\n",
    "    y_val_temp[y_val_temp != class_val] = 0\n",
    "    y_val_temp[y_val_temp == class_val] = 1\n",
    "    lr.fit(wine_train_X,y_temp)  \n",
    "    y_pred = lr.predict_probs(wine_val_X)\n",
    "    y_pred_bool = np.array(y_pred > y_pred_prob_final)\n",
    "    y_pred_final[y_pred_bool] = class_val\n",
    "    y_pred_prob_final[y_pred_bool] = y_pred[y_pred_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.536281179138322"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(wine_val_Y, y_pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE vs ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wine_train_X.copy()\n",
    "df['target'] = wine_train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = wine_val_X.copy()\n",
    "df_val['target'] = wine_val_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.855062</td>\n",
       "      <td>0.279546</td>\n",
       "      <td>0.334155</td>\n",
       "      <td>6.379594</td>\n",
       "      <td>0.045625</td>\n",
       "      <td>35.309558</td>\n",
       "      <td>138.342881</td>\n",
       "      <td>0.994001</td>\n",
       "      <td>3.188616</td>\n",
       "      <td>0.488213</td>\n",
       "      <td>10.527660</td>\n",
       "      <td>5.886273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.837837</td>\n",
       "      <td>0.100915</td>\n",
       "      <td>0.121400</td>\n",
       "      <td>4.985762</td>\n",
       "      <td>0.022126</td>\n",
       "      <td>17.018437</td>\n",
       "      <td>42.086619</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.151248</td>\n",
       "      <td>0.113141</td>\n",
       "      <td>1.229251</td>\n",
       "      <td>0.880908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.712500</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>0.991700</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.500000</td>\n",
       "      <td>0.993730</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.775000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996047</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.010300</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.050000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed_acidity  volatile_acidity  citric_acid  residual_sugar  \\\n",
       "count    3526.000000       3526.000000  3526.000000     3526.000000   \n",
       "mean        6.855062          0.279546     0.334155        6.379594   \n",
       "std         0.837837          0.100915     0.121400        4.985762   \n",
       "min         3.900000          0.080000     0.000000        0.600000   \n",
       "25%         6.300000          0.210000     0.270000        1.712500   \n",
       "50%         6.800000          0.260000     0.320000        5.200000   \n",
       "75%         7.300000          0.320000     0.390000        9.775000   \n",
       "max        14.200000          1.100000     1.660000       31.600000   \n",
       "\n",
       "         chlorides  free_sulfur_dioxide  total_sulfur_dioxide      density  \\\n",
       "count  3526.000000          3526.000000           3526.000000  3526.000000   \n",
       "mean      0.045625            35.309558            138.342881     0.994001   \n",
       "std       0.022126            17.018437             42.086619     0.002921   \n",
       "min       0.012000             2.000000             10.000000     0.987110   \n",
       "25%       0.035000            23.000000            109.000000     0.991700   \n",
       "50%       0.043000            34.000000            134.500000     0.993730   \n",
       "75%       0.050000            46.000000            167.000000     0.996047   \n",
       "max       0.346000           289.000000            440.000000     1.010300   \n",
       "\n",
       "                pH    sulphates      alcohol       target  \n",
       "count  3526.000000  3526.000000  3526.000000  3526.000000  \n",
       "mean      3.188616     0.488213    10.527660     5.886273  \n",
       "std       0.151248     0.113141     1.229251     0.880908  \n",
       "min       2.720000     0.250000     8.000000     3.000000  \n",
       "25%       3.090000     0.410000     9.500000     5.000000  \n",
       "50%       3.180000     0.470000    10.400000     6.000000  \n",
       "75%       3.280000     0.550000    11.400000     6.000000  \n",
       "max       3.810000     1.080000    14.050000     9.000000  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.037</td>\n",
       "      <td>42.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.98880</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.034</td>\n",
       "      <td>17.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.117</td>\n",
       "      <td>40.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.99380</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.059</td>\n",
       "      <td>29.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.99177</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.41</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.27</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.038</td>\n",
       "      <td>33.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.99124</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.42</td>\n",
       "      <td>12.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "710             6.6              0.28         0.34            0.80      0.037   \n",
       "3128            6.7              0.15         0.32            7.90      0.034   \n",
       "1750            6.7              0.61         0.21            1.65      0.117   \n",
       "73              6.5              0.22         0.28            3.70      0.059   \n",
       "2163            6.9              0.44         0.27            5.00      0.038   \n",
       "\n",
       "      free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "710                  42.0                 119.0  0.98880  3.03       0.37   \n",
       "3128                 17.0                  81.0  0.99512  3.29       0.31   \n",
       "1750                 40.0                 240.0  0.99380  3.11       0.57   \n",
       "73                   29.0                 151.0  0.99177  3.23       0.41   \n",
       "2163                 33.0                 166.0  0.99124  3.20       0.42   \n",
       "\n",
       "      alcohol  target  \n",
       "710      12.5       6  \n",
       "3128     10.0       6  \n",
       "1750      9.3       5  \n",
       "73       12.1       7  \n",
       "2163     12.2       6  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for classes: 3, 4\n",
      "Running for classes: 3, 5\n",
      "Running for classes: 3, 6\n",
      "Running for classes: 3, 7\n",
      "Running for classes: 3, 8\n",
      "Running for classes: 3, 9\n",
      "Running for classes: 4, 3\n",
      "Running for classes: 4, 5\n",
      "Running for classes: 4, 6\n",
      "Running for classes: 4, 7\n",
      "Running for classes: 4, 8\n",
      "Running for classes: 4, 9\n",
      "Running for classes: 5, 3\n",
      "Running for classes: 5, 4\n",
      "Running for classes: 5, 6\n",
      "Running for classes: 5, 7\n",
      "Running for classes: 5, 8\n",
      "Running for classes: 5, 9\n",
      "Running for classes: 6, 3\n",
      "Running for classes: 6, 4\n",
      "Running for classes: 6, 5\n",
      "Running for classes: 6, 7\n",
      "Running for classes: 6, 8\n",
      "Running for classes: 6, 9\n",
      "Running for classes: 7, 3\n",
      "Running for classes: 7, 4\n",
      "Running for classes: 7, 5\n",
      "Running for classes: 7, 6\n",
      "Running for classes: 7, 8\n",
      "Running for classes: 7, 9\n",
      "Running for classes: 8, 3\n",
      "Running for classes: 8, 4\n",
      "Running for classes: 8, 5\n",
      "Running for classes: 8, 6\n",
      "Running for classes: 8, 7\n",
      "Running for classes: 8, 9\n",
      "Running for classes: 9, 3\n",
      "Running for classes: 9, 4\n",
      "Running for classes: 9, 5\n",
      "Running for classes: 9, 6\n",
      "Running for classes: 9, 7\n",
      "Running for classes: 9, 8\n"
     ]
    }
   ],
   "source": [
    "y_pred_counts = np.array([defaultdict(int) for i in range(len(wine_val_Y))])\n",
    "perm = permutations(list(range(3,10)), 2)\n",
    "for class_a, class_b in perm:\n",
    "    if(class_a == class_b):\n",
    "        continue\n",
    "    print(\"Running for classes: {0}, {1}\".format(class_a, class_b))\n",
    "\n",
    "    '''\n",
    "    Setting up temporary X_train and Y_train\n",
    "    '''\n",
    "    df_train = df[(df['target'] == class_a) | (df['target'] == class_b)]\n",
    "    x_temp = df_train.iloc[:,df_train.columns != 'target'].copy()\n",
    "    y_temp = df_train.iloc[:,df_train.columns == 'target'].copy()\n",
    "    y_temp[y_temp != class_a] = 0\n",
    "    y_temp[y_temp == class_a] = 1\n",
    "\n",
    "    '''\n",
    "    Setting up temporary X_val and Y_val\n",
    "    '''\n",
    "    df_temp = df_val#[(df_val['target'] == class_a) | (df_val['target'] == class_b)]\n",
    "    x_val_temp = df_temp.iloc[:,df_temp.columns != 'target'].copy()\n",
    "    y_val_temp = df_temp.iloc[:,df_temp.columns == 'target'].copy()\n",
    "    y_val_temp[y_val_temp != class_a] = 0\n",
    "    y_val_temp[y_val_temp == class_a] = 1\n",
    "\n",
    "    '''\n",
    "    Model Training\n",
    "    '''      \n",
    "    lr = MyLogisticRegresson(0.1, 500)\n",
    "    lr.fit(x_temp,y_temp)  \n",
    "    y_pred = np.array(lr.predict(x_val_temp))\n",
    "    for i, y in enumerate(y_pred):\n",
    "        if(int(y) == 1):\n",
    "            y_pred_counts[i][class_a] += 1\n",
    "        else:\n",
    "            y_pred_counts[i][class_b] += 1\n",
    "\n",
    "y_pred_final = [max(d, key=lambda k: d[k]) if bool(d) == True else None for d in y_pred_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5396825396825397"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_pred_final, wine_val_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "1. Both One Vs One and One vs All give accuracy of about ~53%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
